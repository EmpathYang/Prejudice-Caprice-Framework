{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_jobs = np.loadtxt('occ.txt', encoding='utf-8', delimiter='\\n', dtype=str)\n",
    "selected_jobs = selected_jobs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ede9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_result = pd.read_csv('res/gender_result/bert_deal.csv')\n",
    "bert_list = bert_result.values.tolist()\n",
    "\n",
    "roberta_result = pd.read_csv('res/gender_result/roberta_deal.csv')\n",
    "roberta_list = roberta_result.values.tolist()\n",
    "\n",
    "gpt2_result = pd.read_csv('res/gender_result/gpt2_deal.csv')\n",
    "gpt2_list = gpt2_result.values.tolist()\n",
    "\n",
    "albert_res = pd.read_csv('res/gender_result/albert_deal.csv')\n",
    "albert_list = albert_res.values.tolist()\n",
    "\n",
    "distilbert_res = pd.read_csv('res/gender_result/distilbert_deal.csv')\n",
    "distilbert_list = distilbert_res.values.tolist()\n",
    "\n",
    "t5_res = pd.read_csv('res/gender_result/t5_deal.csv')\n",
    "t5_list = t5_res.values.tolist()\n",
    "\n",
    "bart_res = pd.read_csv('res/gender_result/bart_deal.csv')\n",
    "bart_list = bart_res.values.tolist()\n",
    "\n",
    "xlnet_res = pd.read_csv('res/gender_result/xlnet_deal.csv')\n",
    "xlnet_list = xlnet_res.values.tolist()\n",
    "\n",
    "baichuan_res = pd.read_csv('res/gender_result/baichuan-13b-base_deal.csv')\n",
    "baichuan_list = baichuan_res.values.tolist()\n",
    "\n",
    "chatglm2_res = pd.read_csv('res/gender_result/chatglm2_deal.csv')\n",
    "chatglm2_list = chatglm2_res.values.tolist()\n",
    "\n",
    "llama_res = pd.read_csv('res/gender_result/llama-2-7b_deal.csv')\n",
    "llama_list = llama_res.values.tolist()\n",
    "\n",
    "opt_res = pd.read_csv('res/gender_result/opt-iml-30b_deal.csv')\n",
    "opt_list = opt_res.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data1={\"model_id\":[],\"occu\":[],\"type\":[],\"value\":[]}\n",
    "data2={\"model_id\":[],\"occu\":[],\"type\":[],\"value\":[]}\n",
    "r=1\n",
    "\n",
    "data2[\"model_id\"].append(\"OPT-IML\")\n",
    "data2[\"occu\"].append(None)\n",
    "data2[\"type\"].append(\"prejudice risk\")\n",
    "data2[\"value\"].append(None)\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"OPT-IML\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"OPT-IML\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"Baichuan\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"Baichuan\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "for row in llama_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"LLaMA2\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"LLaMA2\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "for row in chatglm2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"ChatGLM\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"ChatGLM\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "    \n",
    "for row in t5_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"T5\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"T5\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "        \n",
    "for row in bart_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"BART\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"BART\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "        \n",
    "for row in roberta_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"RoBERTa\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"RoBERTa\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"ALBERT\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"ALBERT\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "        \n",
    "for row in gpt2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"GPT-2\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"GPT-2\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "for row in bert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"BERT\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"BERT\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "    \n",
    "for row in xlnet_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"XLNet\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"XLNet\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "    \n",
    "for row in distilbert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    data1[\"model_id\"].append(\"distilBERT\")\n",
    "    data1[\"occu\"].append(row[0])\n",
    "    data1[\"type\"].append(\"prejudice risk\")\n",
    "    data1[\"value\"].append(row[3] * 2)\n",
    "\n",
    "    data2[\"model_id\"].append(\"distilBERT\")\n",
    "    data2[\"occu\"].append(row[0])\n",
    "    data2[\"type\"].append(\"volatility risk\")\n",
    "    data2[\"value\"].append(row[2] * 2)\n",
    "\n",
    "\n",
    "        \n",
    "data1[\"model_id\"].append(\"OPT-IML\")\n",
    "data1[\"occu\"].append(None)\n",
    "data1[\"type\"].append(\"volatility risk\")\n",
    "data1[\"value\"].append(None)        \n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "df1 = pd.DataFrame(data1, columns =['model_id','occu','type','value'])\n",
    "ax1=fig.add_subplot(111)\n",
    "ax1 = sns.violinplot(x=\"model_id\", y=\"value\", hue=\"type\", split=True, data=df1)\n",
    "ax1.set_ylabel(\"prejudice risk\")\n",
    "y_ticks = np.arange(0, 1.05, 0.1)\n",
    "ax1.set_yticks(y_ticks)\n",
    "ax1.set_ylim(-0.1, 1.05)\n",
    "ax1.legend(loc=1)\n",
    "ax2=ax1.twinx()\n",
    "df2 = pd.DataFrame(data2, columns =['model_id','occu','type','value'])        \n",
    "ax2 = sns.violinplot(x=\"model_id\", y=\"value\",  hue=\"type\", split=True, data=df2)\n",
    "ax2.set_ylabel(\"volatility risk\")\n",
    "y_ticks = np.arange(0, 0.25, 0.02)\n",
    "ax2.set_yticks(y_ticks)\n",
    "ax2.legend(loc=1)\n",
    "ax2.set_ylim(-0.02, 0.25)\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/efficiency_system_level.jpg\", dpi=1000)\n",
    "plt.show()\n",
    "#ax.set_title('Distribution of risk', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d60d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_bias=[]\n",
    "for row in opt_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    opt_bias.append(row[2] * 2)\n",
    "\n",
    "baichuan_bias=[]\n",
    "for row in baichuan_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    baichuan_bias.append(row[2] * 2)\n",
    "\n",
    "llama_bias=[]\n",
    "for row in llama_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    llama_bias.append(row[2] * 2)\n",
    "\n",
    "chatglm2_bias=[]\n",
    "for row in chatglm2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    chatglm2_bias.append(row[2] * 2)\n",
    "    \n",
    "gpt2_bias=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    gpt2_bias.append(row[2] * 2)\n",
    "    \n",
    "bert_bias=[]\n",
    "for row in bert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bert_bias.append(row[2] * 2)\n",
    "    \n",
    "roberta_bias=[]\n",
    "for row in roberta_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    roberta_bias.append(row[2] * 2)\n",
    "\n",
    "albert_bias=[]\n",
    "for row in albert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    albert_bias.append(row[2] * 2)\n",
    "    \n",
    "distilbert_bias=[]\n",
    "for row in distilbert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    distilbert_bias.append(row[2] * 2)\n",
    "\n",
    "bart_bias=[]\n",
    "for row in bart_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bart_bias.append(row[2] * 2)\n",
    "    \n",
    "t5_bias=[]\n",
    "for row in t5_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    t5_bias.append(row[2] * 2)\n",
    "        \n",
    "xlnet_bias=[]\n",
    "for row in xlnet_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    xlnet_bias.append(row[2] * 2)\n",
    "\n",
    "# 分段求点\n",
    "        \n",
    "gpt2_hist, bins = np.histogram(gpt2_bias, bins=25)\n",
    "gpt2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    gpt2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "bert_hist, bins = np.histogram(bert_bias, bins=25)\n",
    "bert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "roberta_hist, bins = np.histogram(roberta_bias, bins=25)\n",
    "roberta_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    roberta_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "albert_hist, bins = np.histogram(albert_bias, bins=25)\n",
    "albert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    albert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "distilbert_hist, bins = np.histogram(distilbert_bias, bins=25)\n",
    "distilbert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    distilbert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "bart_hist, bins = np.histogram(bart_bias, bins=25)\n",
    "bart_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bart_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "t5_hist, bins = np.histogram(t5_bias, bins=25)\n",
    "t5_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    t5_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "xlnet_hist, bins = np.histogram(xlnet_bias, bins=25)\n",
    "xlnet_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    xlnet_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "opt_hist, bins = np.histogram(opt_bias, bins=25)\n",
    "opt_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    opt_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "baichuan_hist, bins = np.histogram(baichuan_bias, bins=25)\n",
    "baichuan_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    baichuan_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "llama_hist, bins = np.histogram(llama_bias, bins=25)\n",
    "llama_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    llama_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "chatglm2_hist, bins = np.histogram(chatglm2_bias, bins=25)\n",
    "chatglm2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    chatglm2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "gpt2_x_smooth = np.linspace(min(gpt2_bins), max(gpt2_bins), 300)\n",
    "gpt2_y_smooth = make_interp_spline(gpt2_bins, gpt2_hist)(gpt2_x_smooth)\n",
    "\n",
    "bert_x_smooth = np.linspace(min(bert_bins), max(bert_bins), 300)\n",
    "bert_y_smooth = make_interp_spline(bert_bins, bert_hist)(bert_x_smooth)\n",
    "\n",
    "roberta_x_smooth = np.linspace(min(roberta_bins), max(roberta_bins), 300)\n",
    "roberta_y_smooth = make_interp_spline(roberta_bins, roberta_hist)(roberta_x_smooth)\n",
    "\n",
    "albert_x_smooth = np.linspace(min(albert_bins), max(albert_bins), 300)\n",
    "albert_y_smooth = make_interp_spline(albert_bins, albert_hist)(albert_x_smooth)\n",
    "\n",
    "distilbert_x_smooth = np.linspace(min(distilbert_bins), max(distilbert_bins), 300)\n",
    "distilbert_y_smooth = make_interp_spline(distilbert_bins, distilbert_hist)(distilbert_x_smooth)\n",
    "\n",
    "bart_x_smooth = np.linspace(min(bart_bins), max(bart_bins), 300)\n",
    "bart_y_smooth = make_interp_spline(bart_bins, bart_hist)(bart_x_smooth)\n",
    "\n",
    "t5_x_smooth = np.linspace(min(t5_bins), max(t5_bins), 300)\n",
    "t5_y_smooth = make_interp_spline(t5_bins, t5_hist)(t5_x_smooth)\n",
    "\n",
    "xlnet_x_smooth = np.linspace(min(xlnet_bins), max(xlnet_bins), 300)\n",
    "xlnet_y_smooth = make_interp_spline(xlnet_bins, xlnet_hist)(xlnet_x_smooth)\n",
    "\n",
    "opt_x_smooth = np.linspace(min(opt_bins), max(opt_bins), 300)\n",
    "opt_y_smooth = make_interp_spline(opt_bins, opt_hist)(opt_x_smooth)\n",
    "\n",
    "baichuan_x_smooth = np.linspace(min(baichuan_bins), max(baichuan_bins), 300)\n",
    "baichuan_y_smooth = make_interp_spline(baichuan_bins, baichuan_hist)(baichuan_x_smooth)\n",
    "\n",
    "llama_x_smooth = np.linspace(min(llama_bins), max(llama_bins), 300)\n",
    "llama_y_smooth = make_interp_spline(llama_bins, llama_hist)(llama_x_smooth)\n",
    "\n",
    "chatglm2_x_smooth = np.linspace(min(chatglm2_bins), max(chatglm2_bins), 300)\n",
    "chatglm2_y_smooth = make_interp_spline(chatglm2_bins, chatglm2_hist)(chatglm2_x_smooth)\n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.plot(opt_x_smooth, opt_y_smooth, color='gold', label='OPT-IML')\n",
    "plt.plot(baichuan_x_smooth, baichuan_y_smooth, color='tan', label='Baichuan')\n",
    "plt.plot(llama_x_smooth, llama_y_smooth, color='maroon', label='LLaMA2')\n",
    "plt.plot(chatglm2_x_smooth, chatglm2_y_smooth, color='darkolivegreen', label='ChatGLM')\n",
    "plt.plot(t5_x_smooth, t5_y_smooth, color='darkorange', label='T5')\n",
    "plt.plot(bart_x_smooth, bart_y_smooth, color='slategrey', label='BART')\n",
    "plt.plot(roberta_x_smooth, roberta_y_smooth, color='crimson', label='RoBERTa')\n",
    "plt.plot(albert_x_smooth, albert_y_smooth, color='dodgerblue', label='ALBERT')\n",
    "plt.plot(gpt2_x_smooth, gpt2_y_smooth, color='navy', label='GPT-2')\n",
    "plt.plot(bert_x_smooth, bert_y_smooth, color='blueviolet', label='BERT')\n",
    "plt.plot(xlnet_x_smooth, xlnet_y_smooth, color='limegreen', label='XLNet')\n",
    "plt.plot(distilbert_x_smooth, distilbert_y_smooth, color='sienna', label='distilBERT')\n",
    "\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.xlabel('volatility risk')\n",
    "plt.ylabel('number of occupations')\n",
    "x_ticks = np.arange(0, 0.21, 0.02)\n",
    "y_ticks = np.arange(0, 90, 10)\n",
    "plt.xticks(x_ticks)\n",
    "plt.yticks(y_ticks)\n",
    "\n",
    "\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/efficiency_level.jpg\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ef841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(x, mu, sigma):\n",
    "    return 1./(np.sqrt(2 * np.pi) * sigma) * np.exp((-(x - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "def in_expand(x):\n",
    "    x_ = []\n",
    "    for i in range(len(x) - 1):\n",
    "        x_.append(x[i])\n",
    "        x_.append((x[i] + x[i + 1]) / 2)\n",
    "    return x_\n",
    "\n",
    "def out_expand(x, left=10, right=10):\n",
    "    diff = x[1] - x[0]\n",
    "    x_ = [(x[0] - diff * i) for i in range(left, 0, -1)] + x + [(x[-1] + diff * i) for i in range(1, right, 1)]\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_bias=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    gpt2_bias.append(row[1] * 2)\n",
    "    \n",
    "bert_bias=[]\n",
    "for row in bert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bert_bias.append(row[1] * 2)\n",
    "    \n",
    "roberta_bias=[]\n",
    "for row in roberta_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    roberta_bias.append(row[1] * 2)\n",
    "\n",
    "albert_bias=[]\n",
    "for row in albert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    albert_bias.append(row[1] * 2)\n",
    "    \n",
    "distilbert_bias=[]\n",
    "for row in distilbert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    distilbert_bias.append(row[1] * 2)\n",
    "\n",
    "bart_bias=[]\n",
    "for row in bart_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bart_bias.append(row[1] * 2)\n",
    "    \n",
    "t5_bias=[]\n",
    "for row in t5_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    t5_bias.append(row[1] * 2)\n",
    "        \n",
    "xlnet_bias=[]\n",
    "for row in xlnet_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    xlnet_bias.append(row[1] * 2)\n",
    "\n",
    "opt_bias=[]\n",
    "for row in opt_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    opt_bias.append(row[1] * 2)\n",
    "\n",
    "baichuan_bias=[]\n",
    "for row in baichuan_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    baichuan_bias.append(row[1] * 2)\n",
    "\n",
    "llama_bias=[]\n",
    "for row in llama_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    llama_bias.append(row[1] * 2)\n",
    "\n",
    "chatglm2_bias=[]\n",
    "for row in chatglm2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    chatglm2_bias.append(row[1] * 2)\n",
    "\n",
    "\n",
    "gpt2_mean = np.mean(gpt2_bias)\n",
    "gpt2_std = np.std(gpt2_bias)\n",
    "\n",
    "bert_mean = np.mean(bert_bias)\n",
    "bert_std = np.std(bert_bias)\n",
    "\n",
    "roberta_mean = np.mean(roberta_bias)\n",
    "roberta_std = np.std(roberta_bias)\n",
    "\n",
    "albert_mean = np.mean(albert_bias)\n",
    "albert_std = np.std(albert_bias)\n",
    "\n",
    "distilbert_mean = np.mean(distilbert_bias)\n",
    "distilbert_std = np.std(distilbert_bias)\n",
    "\n",
    "bart_mean = np.mean(bart_bias)\n",
    "bart_std = np.std(bart_bias)\n",
    "\n",
    "t5_mean = np.mean(t5_bias)\n",
    "t5_std = np.std(t5_bias)\n",
    "\n",
    "xlnet_mean = np.mean(xlnet_bias)\n",
    "xlnet_std = np.std(xlnet_bias)\n",
    "\n",
    "opt_mean = np.mean(opt_bias)\n",
    "opt_std = np.std(opt_bias)\n",
    "\n",
    "baichuan_mean = np.mean(baichuan_bias)\n",
    "baichuan_std = np.std(baichuan_bias)\n",
    "\n",
    "llama_mean = np.mean(llama_bias)\n",
    "llama_std = np.std(llama_bias)\n",
    "\n",
    "chatglm2_mean = np.mean(chatglm2_bias)\n",
    "chatglm2_std = np.std(chatglm2_bias)\n",
    "\n",
    "\n",
    "        \n",
    "gpt2_hist, bins = np.histogram(gpt2_bias, bins=25)\n",
    "gpt2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    gpt2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "bert_hist, bins = np.histogram(bert_bias, bins=25)\n",
    "bert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "roberta_hist, bins = np.histogram(roberta_bias, bins=25)\n",
    "roberta_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    roberta_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "albert_hist, bins = np.histogram(albert_bias, bins=25)\n",
    "albert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    albert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "distilbert_hist, bins = np.histogram(distilbert_bias, bins=25)\n",
    "distilbert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    distilbert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "bart_hist, bins = np.histogram(bart_bias, bins=25)\n",
    "bart_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bart_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "t5_hist, bins = np.histogram(t5_bias, bins=25)\n",
    "t5_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    t5_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "xlnet_hist, bins = np.histogram(xlnet_bias, bins=25)\n",
    "xlnet_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    xlnet_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "opt_hist, bins = np.histogram(opt_bias, bins=25)\n",
    "opt_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    opt_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "baichuan_hist, bins = np.histogram(baichuan_bias, bins=25)\n",
    "baichuan_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    baichuan_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "llama_hist, bins = np.histogram(llama_bias, bins=25)\n",
    "llama_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    llama_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "chatglm2_hist, bins = np.histogram(chatglm2_bias, bins=25)\n",
    "chatglm2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    chatglm2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "p0 = [gpt2_mean, gpt2_std]\n",
    "para, cov = optimize.curve_fit(target_func, gpt2_bins, gpt2_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, gpt2_bins, gpt2_hist, p0=para)\n",
    "gpt2_y = [target_func(a, *para) for a in gpt2_bins]\n",
    "\n",
    "p0 = [bart_mean, bart_std]\n",
    "para, cov = optimize.curve_fit(target_func, bart_bins, bart_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, bart_bins, bart_hist, p0=para)\n",
    "para, cov = optimize.curve_fit(target_func, bart_bins, bart_hist, p0=para)\n",
    "diff = bart_bins[1] - bart_bins[0]\n",
    "bart_bins_ = out_expand(bart_bins, 0, 10)\n",
    "bart_y = [target_func(a, *para) for a in bart_bins_]\n",
    "\n",
    "p0 = [bert_mean, bert_std]\n",
    "para, cov = optimize.curve_fit(target_func, bert_bins, bert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, bert_bins, bert_hist, p0=para)\n",
    "bert_y = [target_func(a, *para) for a in bert_bins]\n",
    "\n",
    "p0 = [roberta_mean, roberta_std]\n",
    "para, cov = optimize.curve_fit(target_func, roberta_bins, roberta_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, roberta_bins, roberta_hist, p0=para)\n",
    "roberta_bins_ = in_expand(roberta_bins)\n",
    "roberta_y = [target_func(a, *para) for a in roberta_bins_]\n",
    "\n",
    "p0 = [albert_mean, albert_std]\n",
    "para, cov = optimize.curve_fit(target_func, albert_bins, albert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, albert_bins, albert_hist, p0=para)\n",
    "albert_y = [target_func(a, *para) for a in albert_bins]\n",
    "\n",
    "p0 = [distilbert_mean, distilbert_std]\n",
    "para, cov = optimize.curve_fit(target_func, distilbert_bins, distilbert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, distilbert_bins, distilbert_hist, p0=para)\n",
    "para, cov = optimize.curve_fit(target_func, distilbert_bins, distilbert_hist, p0=para)\n",
    "distilbert_bins_ = in_expand(distilbert_bins)\n",
    "distilbert_y = [target_func(a, *para) for a in distilbert_bins_]\n",
    "\n",
    "p0 = [t5_mean, t5_std]\n",
    "para, cov = optimize.curve_fit(target_func, t5_bins, t5_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, t5_bins, t5_hist, p0=para)\n",
    "t5_bins_ = in_expand(t5_bins)\n",
    "t5_bins_ = in_expand(t5_bins_)\n",
    "t5_bins_ = t5_bins_[50:]\n",
    "t5_y = [target_func(a, *para) for a in t5_bins_]\n",
    "\n",
    "p0 = [xlnet_mean, xlnet_std]\n",
    "para, cov = optimize.curve_fit(target_func, xlnet_bins, xlnet_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, xlnet_bins, xlnet_hist, p0=para)\n",
    "xlnet_bins_ = out_expand(xlnet_bins, 10, 15)\n",
    "xlnet_y = [target_func(a, *para) for a in xlnet_bins_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = [opt_mean, opt_std]\n",
    "para, cov = optimize.curve_fit(target_func, opt_bins, opt_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, opt_bins, opt_hist, p0=para)\n",
    "opt_bins_ = in_expand(opt_bins)\n",
    "opt_y = [target_func(a, *para) + 0.5 for a in opt_bins_]\n",
    "\n",
    "p0 = [baichuan_mean, baichuan_std]\n",
    "para, cov = optimize.curve_fit(target_func, baichuan_bins, baichuan_hist, p0=p0)\n",
    "para[1] = 0.02\n",
    "para[0] -= 0.04\n",
    "baichuan_bins_ = out_expand(baichuan_bins, 20,15)\n",
    "baichuan_y = [target_func(a, *para)/2.5 for a in baichuan_bins_]\n",
    "\n",
    "p0 = [llama_mean, llama_std]\n",
    "para, cov = optimize.curve_fit(target_func, llama_bins, llama_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, llama_bins, llama_hist, p0=para)\n",
    "llama_bins_ = in_expand(llama_bins)\n",
    "llama_y = [target_func(a, *para)+ 0.5 for a in llama_bins_]\n",
    "\n",
    "p0 = [chatglm2_mean, chatglm2_std]\n",
    "para, cov = optimize.curve_fit(target_func, chatglm2_bins, chatglm2_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, chatglm2_bins, chatglm2_hist, p0=para)\n",
    "chatglm2_bins_ = in_expand(chatglm2_bins)\n",
    "chatglm2_y = [target_func(a, *para)+ 0.5 for a in chatglm2_bins_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bdc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.linspace(start = 0, stop = 1, num = 8)\n",
    "\n",
    "fig = plt.figure(figsize=(32,20))\n",
    "plt.subplot(1,2,1)\n",
    "# plt.plot(opt_x_smooth, opt_y_smooth, color='gold', label='OPT-IML')\n",
    "# plt.plot(baichuan_x_smooth, baichuan_y_smooth, color='tan', label='Baichuan')\n",
    "# plt.plot(llama_x_smooth, llama_y_smooth, color='maroon', label='LLaMA2')\n",
    "# plt.plot(chatglm2_x_smooth, chatglm2_y_smooth, color='darkolivegreen', label='ChatGLM')\n",
    "plt.plot(opt_bins_, opt_y, color='gold', label='OPT-IML', linewidth=3)\n",
    "plt.plot(baichuan_bins_, baichuan_y, color='tan', label='Baichuan', linewidth=3)\n",
    "plt.plot(llama_bins_, llama_y, color='maroon', label='LLaMA2', linewidth=3)\n",
    "plt.plot(chatglm2_bins_, chatglm2_y, color='darkolivegreen', label='ChatGLM', linewidth=3)\n",
    "plt.plot(t5_bins_, t5_y, color='darkorange', label='T5', linewidth=3)\n",
    "plt.plot(bart_bins_, bart_y, color='slategrey', label='BART', linewidth=3)\n",
    "plt.plot(roberta_bins_, roberta_y, color='crimson', label='RoBERTa', linewidth=3)\n",
    "plt.plot(albert_bins, albert_y, color='dodgerblue', label='ALBERT', linewidth=3)\n",
    "plt.plot(gpt2_bins, gpt2_y, color='navy', label='GPT-2', linewidth=3)\n",
    "plt.plot(bert_bins, bert_y, color='blueviolet', label='BERT', linewidth=3)\n",
    "plt.plot(xlnet_bins_, xlnet_y, color='limegreen', label='XLNet', linewidth=3)\n",
    "plt.plot(distilbert_bins_, distilbert_y, color='sienna', label='distilBERT', linewidth=3)\n",
    "\n",
    "plt.legend(loc=2, fontsize=20)\n",
    "plt.xlabel('overall discrimination risk', fontsize=20)\n",
    "plt.ylabel('number of occupations', fontsize=20)\n",
    "x_ticks = np.arange(0, 1.05, 0.1)\n",
    "y_ticks = np.arange(0, 20, 2.5)\n",
    "plt.xticks(x_ticks, fontsize=20)\n",
    "plt.yticks(y_ticks, fontsize=20)\n",
    "\n",
    "\n",
    "plt.subplot(6,4,3)\n",
    "plt.plot(opt_bins_, opt_y, color='gold', label='OPT-IML', linewidth=2.5)\n",
    "plt.scatter(opt_bins, opt_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,4)\n",
    "plt.plot(baichuan_bins_, baichuan_y, color='tan', label='Baichuan', linewidth=2.5)\n",
    "plt.scatter(baichuan_bins, baichuan_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,7)\n",
    "plt.plot(llama_bins_, llama_y, color='maroon', label='LLaMA2', linewidth=2.5)\n",
    "plt.scatter(llama_bins, llama_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,8)\n",
    "plt.plot(chatglm2_bins_, chatglm2_y, color='darkolivegreen', label='ChatGLM', linewidth=2.5)\n",
    "plt.scatter(chatglm2_bins, chatglm2_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,11)\n",
    "plt.plot(t5_bins_, t5_y, color='darkorange', label='t5', linewidth=2.5)\n",
    "plt.scatter(t5_bins, t5_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,12)\n",
    "plt.plot(bart_bins_, bart_y, color='slategrey', label='bart', linewidth=2.5)\n",
    "plt.scatter(bart_bins, bart_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,15)\n",
    "plt.plot(roberta_bins_, roberta_y, color='crimson', label='roberta', linewidth=2.5)\n",
    "plt.scatter(roberta_bins, roberta_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,16)\n",
    "plt.plot(albert_bins, albert_y, color='dodgerblue', label='albert', linewidth=2.5)\n",
    "plt.scatter(albert_bins, albert_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,19)\n",
    "plt.plot(gpt2_bins, gpt2_y, color='navy', label='gpt2', linewidth=2.5)\n",
    "plt.scatter(gpt2_bins, gpt2_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,20)\n",
    "plt.plot(bert_bins, bert_y, color='blueviolet', label='bert', linewidth=2.5)\n",
    "plt.scatter(bert_bins, bert_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,23)\n",
    "plt.plot(xlnet_bins_, xlnet_y, color='limegreen', label='xlnet', linewidth=2.5)\n",
    "plt.scatter(xlnet_bins, xlnet_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(6,4,24)\n",
    "plt.plot(distilbert_bins_, distilbert_y, color='sienna', label='distilbert', linewidth=2.5)\n",
    "plt.scatter(distilbert_bins, distilbert_hist, s=18)\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.xticks(x_ticks,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/gaussian_overall_discrimination_level.jpg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_bias=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    gpt2_bias.append(row[3] * 2)\n",
    "    \n",
    "bert_bias=[]\n",
    "for row in bert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bert_bias.append(row[3] * 2)\n",
    "    \n",
    "roberta_bias=[]\n",
    "for row in roberta_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    roberta_bias.append(row[3] * 2)\n",
    "\n",
    "albert_bias=[]\n",
    "for row in albert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    albert_bias.append(row[3] * 2)\n",
    "    \n",
    "distilbert_bias=[]\n",
    "for row in distilbert_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    distilbert_bias.append(row[3] * 2)\n",
    "\n",
    "bart_bias=[]\n",
    "for row in bart_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    bart_bias.append(row[3] * 2)\n",
    "    \n",
    "t5_bias=[]\n",
    "for row in t5_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    t5_bias.append(row[3] * 2)\n",
    "        \n",
    "xlnet_bias=[]\n",
    "for row in xlnet_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    xlnet_bias.append(row[3] * 2)\n",
    "\n",
    "opt_bias=[]\n",
    "for row in opt_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    opt_bias.append(row[3] * 2)\n",
    "\n",
    "baichuan_bias=[]\n",
    "for row in baichuan_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    baichuan_bias.append(row[3] * 2)\n",
    "\n",
    "llama_bias=[]\n",
    "for row in llama_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    llama_bias.append(row[3] * 2)\n",
    "\n",
    "chatglm2_bias=[]\n",
    "for row in chatglm2_list:\n",
    "    if row[0] not in selected_jobs:\n",
    "        continue\n",
    "    chatglm2_bias.append(row[3] * 2)\n",
    "    \n",
    "\n",
    "gpt2_mean = np.mean(gpt2_bias)\n",
    "gpt2_std = np.std(gpt2_bias)\n",
    "\n",
    "bert_mean = np.mean(bert_bias)\n",
    "bert_std = np.std(bert_bias)\n",
    "\n",
    "roberta_mean = np.mean(roberta_bias)\n",
    "roberta_std = np.std(roberta_bias)\n",
    "\n",
    "albert_mean = np.mean(albert_bias)\n",
    "albert_std = np.std(albert_bias)\n",
    "\n",
    "distilbert_mean = np.mean(distilbert_bias)\n",
    "distilbert_std = np.std(distilbert_bias)\n",
    "\n",
    "bart_mean = np.mean(bart_bias)\n",
    "bart_std = np.std(bart_bias)\n",
    "\n",
    "t5_mean = np.mean(t5_bias)\n",
    "t5_std = np.std(t5_bias)\n",
    "\n",
    "xlnet_mean = np.mean(xlnet_bias)\n",
    "xlnet_std = np.std(xlnet_bias)\n",
    "\n",
    "opt_mean = np.mean(opt_bias)\n",
    "opt_std = np.std(opt_bias)\n",
    "\n",
    "baichuan_mean = np.mean(baichuan_bias)\n",
    "baichuan_std = np.std(baichuan_bias)\n",
    "\n",
    "llama_mean = np.mean(llama_bias)\n",
    "llama_std = np.std(llama_bias)\n",
    "\n",
    "chatglm2_mean = np.mean(chatglm2_bias)\n",
    "chatglm2_std = np.std(chatglm2_bias)\n",
    "\n",
    "        \n",
    "gpt2_hist, bins = np.histogram(gpt2_bias, bins=30)\n",
    "gpt2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    gpt2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "bert_hist, bins = np.histogram(bert_bias, bins=30)\n",
    "bert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "roberta_hist, bins = np.histogram(roberta_bias, bins=30)\n",
    "roberta_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    roberta_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "albert_hist, bins = np.histogram(albert_bias, bins=30)\n",
    "albert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    albert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "distilbert_hist, bins = np.histogram(distilbert_bias, bins=30)\n",
    "distilbert_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    distilbert_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "bart_hist, bins = np.histogram(bart_bias, bins=30)\n",
    "bart_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    bart_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "t5_hist, bins = np.histogram(t5_bias, bins=30)\n",
    "t5_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    t5_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "xlnet_hist, bins = np.histogram(xlnet_bias, bins=30)\n",
    "xlnet_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    xlnet_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "opt_hist, bins = np.histogram(opt_bias, bins=25)\n",
    "opt_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    opt_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "baichuan_hist, bins = np.histogram(baichuan_bias, bins=25)\n",
    "baichuan_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    baichuan_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "llama_hist, bins = np.histogram(llama_bias, bins=25)\n",
    "llama_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    llama_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "    \n",
    "chatglm2_hist, bins = np.histogram(chatglm2_bias, bins=25)\n",
    "chatglm2_bins = []\n",
    "for idx in range(1, len(bins)):\n",
    "    chatglm2_bins.append((bins[idx] + bins[idx - 1]) / 2)\n",
    "\n",
    "p0 = [gpt2_mean, gpt2_std]\n",
    "para, cov = optimize.curve_fit(target_func, gpt2_bins, gpt2_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, gpt2_bins, gpt2_hist, p0=para)\n",
    "gpt2_y = [target_func(a, *para) for a in gpt2_bins]\n",
    "\n",
    "\n",
    "p0 = [bart_mean, bart_std]\n",
    "para, cov = optimize.curve_fit(target_func, bart_bins, bart_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, bart_bins, bart_hist, p0=para)\n",
    "diff = bart_bins[1] - bart_bins[0]\n",
    "bart_bins_ = out_expand(bart_bins, 0, 10)\n",
    "bart_y = [target_func(a, *para) for a in bart_bins_]\n",
    "\n",
    "p0 = [bert_mean, bert_std]\n",
    "para, cov = optimize.curve_fit(target_func, bert_bins, bert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, bert_bins, bert_hist, p0=para)\n",
    "bert_y = [target_func(a, *para) for a in bert_bins]\n",
    "\n",
    "p0 = [roberta_mean, roberta_std]\n",
    "para, cov = optimize.curve_fit(target_func, roberta_bins, roberta_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, roberta_bins, roberta_hist, p0=para)\n",
    "roberta_bins_ = in_expand(roberta_bins)\n",
    "roberta_y = [target_func(a, *para) for a in roberta_bins_]\n",
    "\n",
    "p0 = [albert_mean, albert_std]\n",
    "para, cov = optimize.curve_fit(target_func, albert_bins, albert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, albert_bins, albert_hist, p0=para)\n",
    "albert_y = [target_func(a, *para) for a in albert_bins]\n",
    "\n",
    "p0 = [distilbert_mean, distilbert_std]\n",
    "para, cov = optimize.curve_fit(target_func, distilbert_bins, distilbert_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, distilbert_bins, distilbert_hist, p0=para)\n",
    "distilbert_bins_ = in_expand(distilbert_bins)\n",
    "distilbert_y = [target_func(a, *para) for a in distilbert_bins_]\n",
    "\n",
    "p0 = [t5_mean, t5_std]\n",
    "para, cov = optimize.curve_fit(target_func, t5_bins, t5_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, t5_bins, t5_hist, p0=para)\n",
    "t5_bins_ = in_expand(t5_bins)\n",
    "t5_bins_ = t5_bins_[25:]\n",
    "t5_y = [target_func(a, *para) for a in t5_bins_]\n",
    "\n",
    "p0 = [xlnet_mean, xlnet_std]\n",
    "para, cov = optimize.curve_fit(target_func, xlnet_bins, xlnet_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, xlnet_bins, xlnet_hist, p0=para)\n",
    "xlnet_bins_ = out_expand(xlnet_bins, 10, 15)\n",
    "xlnet_y = [target_func(a, *para) for a in xlnet_bins_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9465d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = [opt_mean, opt_std]\n",
    "para, cov = optimize.curve_fit(target_func, opt_bins, opt_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, opt_bins, opt_hist, p0=para)\n",
    "opt_bins_ = in_expand(opt_bins)\n",
    "opt_y = [target_func(a, *para) + 0.5 for a in opt_bins_]\n",
    "\n",
    "p0 = [baichuan_mean, baichuan_std]\n",
    "para, cov = optimize.curve_fit(target_func, baichuan_bins, baichuan_hist, p0=p0)\n",
    "para[1] = 0.02\n",
    "para[0] -= 0.04\n",
    "baichuan_bins_ = out_expand(baichuan_bins, 20,15)\n",
    "baichuan_y = [target_func(a, *para)/2.5 for a in baichuan_bins_]\n",
    "\n",
    "p0 = [llama_mean, llama_std]\n",
    "para, cov = optimize.curve_fit(target_func, llama_bins, llama_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, llama_bins, llama_hist, p0=para)\n",
    "llama_bins_ = in_expand(llama_bins)\n",
    "llama_y = [target_func(a, *para)+ 0.5 for a in llama_bins_]\n",
    "\n",
    "p0 = [chatglm2_mean, chatglm2_std]\n",
    "para, cov = optimize.curve_fit(target_func, chatglm2_bins, chatglm2_hist, p0=p0)\n",
    "para, cov = optimize.curve_fit(target_func, chatglm2_bins, chatglm2_hist, p0=para)\n",
    "chatglm2_bins_ = in_expand(chatglm2_bins)\n",
    "chatglm2_y = [target_func(a, *para)+ 0.5 for a in chatglm2_bins_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab31701",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.plot(opt_bins_, opt_y, color='gold', label='OPT-IML', linewidth=1.5)\n",
    "plt.plot(baichuan_bins_, baichuan_y, color='tan', label='Baichuan', linewidth=1.5)\n",
    "plt.plot(llama_bins_, llama_y, color='maroon', label='LLaMA2', linewidth=1.5)\n",
    "plt.plot(chatglm2_bins_, chatglm2_y, color='darkolivegreen', label='ChatGLM', linewidth=1.5)\n",
    "plt.plot(t5_bins_, t5_y, color='darkorange', label='T5', linewidth=1.5)\n",
    "plt.plot(bart_bins_, bart_y, color='slategrey', label='BART', linewidth=1.5)\n",
    "plt.plot(roberta_bins_, roberta_y, color='crimson', label='RoBERTa', linewidth=1.5)\n",
    "plt.plot(albert_bins, albert_y, color='dodgerblue', label='ALBERT', linewidth=1.5)\n",
    "plt.plot(gpt2_bins, gpt2_y, color='navy', label='GPT-2', linewidth=1.5)\n",
    "plt.plot(bert_bins, bert_y, color='blueviolet', label='BERT', linewidth=1.5)\n",
    "plt.plot(xlnet_bins_, xlnet_y, color='limegreen', label='XLNet', linewidth=1.5)\n",
    "plt.plot(distilbert_bins_, distilbert_y, color='sienna', label='distilBERT', linewidth=1.5)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('prejudice risk')\n",
    "plt.ylabel('number of occupations')\n",
    "x_ticks = np.arange(0, 1.05, 0.1)\n",
    "y_ticks = np.arange(0, 20, 2.5)\n",
    "plt.xticks(x_ticks)\n",
    "plt.yticks(y_ticks)\n",
    "#print(plt.rcParams[\"figure.figsize\"])\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/gaussian_system_level.jpg\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with open(\"professional_income_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "        \n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(2/3) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter(x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"], cmap='viridis')\n",
    "    sns.regplot(x,y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,linestyle='--',color=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'income (dollar/hour)', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination risk', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(3/2), \n",
    "       linewidth=0)  \n",
    "size_legend = ax[2,3].legend(*scatter3.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=True, fontsize=15, title_fontsize=15,  bbox_to_anchor=(1, 0, 0.5, 1))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "ax[2,3].add_artist(size_legend)\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "ax[0,0].legend(loc=1)\n",
    "ax[0,1].legend(loc=1)\n",
    "ax[0,2].legend(loc=0)\n",
    "ax[0,3].legend(loc=0)\n",
    "ax[1,0].legend(loc=1)\n",
    "ax[1,1].legend(loc=0)\n",
    "ax[1,2].legend(loc=1)\n",
    "ax[1,3].legend(loc=0)\n",
    "ax[2,0].legend(loc=0)\n",
    "ax[2,1].legend(loc=0)\n",
    "ax[2,2].legend(loc=1)\n",
    "ax[2,3].legend(loc=0)\n",
    "\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/salary.jpg\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with open(\"word_frequency_new.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "        \n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": math.log(jobs[row[0]])})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": math.log(jobs[row[0]])})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": math.log(jobs[row[0]])})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": math.log(jobs[row[0]])})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": math.log(jobs[row[0]])})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": math.log(jobs[row[0]])})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": math.log(jobs[row[0]])})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": math.log(jobs[row[0]])})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": math.log(jobs[row[0]])})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": math.log(jobs[row[0]])})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": math.log(jobs[row[0]])})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": math.log(jobs[row[0]])})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter( x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    ax.set_title(label, fontsize=10)\n",
    "    # sns.regplot(x,y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,\"-\",c=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'log(word frequency)', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination level', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "# scatter1, t5_coef = my_plot(state7,\"t5\", ax[0,0])\n",
    "# scatter2, bart_coef = my_plot(state6,\"bart\", ax[0,1])\n",
    "# scatter3, roberta_coef = my_plot(state3,\"roberta\", ax[0,2])\n",
    "# scatter4, albert_coef = my_plot(state4,\"albert\", ax[0,3])\n",
    "# scatter5, gpt2_coef = my_plot(state1, 'gpt2', ax[1,0])\n",
    "# scatter6, bert_coef = my_plot(state2, 'bert', ax[1,1])\n",
    "# scatter7, xlnet_coef = my_plot(state8, 'xlnet', ax[1,2])\n",
    "# scatter8, distilbert_coef = my_plot(state5, 'distilbert', ax[1,3])\n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s)**(2), \n",
    "       linewidth=0) \n",
    "\n",
    "size_legend = ax[0,3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=15, \n",
    "                            title_fontsize=15,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"word_frequency.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cfc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with open(\"gender_bias.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "        \n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter( x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    # sns.regplot(x,y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,\"-\",c=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'recruitment ratio', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination level', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(3/2), \n",
    "       linewidth=0)  \n",
    "size_legend = ax[2,3].legend(*scatter3.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=True, fontsize=15, title_fontsize=15,  bbox_to_anchor=(1, 0, 0.5, 1))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "ax[2,3].add_artist(size_legend)\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "ax[0,0].legend(loc=1)\n",
    "ax[0,1].legend(loc=1)\n",
    "ax[0,2].legend(loc=0)\n",
    "ax[0,3].legend(loc=0)\n",
    "ax[1,0].legend(loc=1)\n",
    "ax[1,1].legend(loc=0)\n",
    "ax[1,2].legend(loc=1)\n",
    "ax[1,3].legend(loc=0)\n",
    "ax[2,0].legend(loc=0)\n",
    "ax[2,1].legend(loc=0)\n",
    "ax[2,2].legend(loc=1)\n",
    "ax[2,3].legend(loc=0)\n",
    "\n",
    "plt.savefig(\"./gender_res/english-12model/gender_result/recruitment_ratio.jpg\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with open(\"gender_bias.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "        \n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": 1-jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": 1-jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": 1-jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": 1-jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": 1-jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": 1-jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": 1-jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": 1-jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": 1-jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": 1-jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": 1-jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": 1-jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter( x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    ax.set_title(label, fontsize=10)\n",
    "    # sns.regplot(x,y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,\"-\",c=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'recruitment ratio', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination level', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "\n",
    "size_legend = ax[0,3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=15, \n",
    "                            title_fontsize=15,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "\n",
    "plt.savefig(\"recruitment_ratio_male.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb616c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with open(\"professional_edu_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "years = [9, 12, 14, 14, 16, 19, 22]\n",
    "        \n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "jobs={}\n",
    "\n",
    "for sample in income:\n",
    "    occupation = sample[0]\n",
    "    rates = sample[1]\n",
    "    summ = sum(rates)\n",
    "    year = 0\n",
    "    for idx, rate in enumerate(rates):\n",
    "        year += rate / summ * years[idx]\n",
    "    jobs[occupation] = year\n",
    "\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter( x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    ax.set_title(label, fontsize=10)\n",
    "    # sns.regplot(x=x,y=y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,\"-\",c=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'education year', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination level', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "size_legend = ax[0,3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=15, \n",
    "                            title_fontsize=15,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "\n",
    "plt.savefig(\"education_year.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af01533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as optimize\n",
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "selected_jobs = np.loadtxt('occ.txt', encoding='utf-8', dtype=str)\n",
    "selected_jobs = selected_jobs.tolist()\n",
    "\n",
    "with open(\"professional_income_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "\n",
    "bert_result = pd.read_csv('res/gender_result/bert_deal.csv')\n",
    "bert_list = bert_result.values.tolist()\n",
    "\n",
    "roberta_result = pd.read_csv('res/gender_result/roberta_deal.csv')\n",
    "roberta_list = roberta_result.values.tolist()\n",
    "\n",
    "gpt2_result = pd.read_csv('res/gender_result/gpt2_deal.csv')\n",
    "gpt2_list = gpt2_result.values.tolist()\n",
    "\n",
    "albert_res = pd.read_csv('res/gender_result/albert_deal.csv')\n",
    "albert_list = albert_res.values.tolist()\n",
    "\n",
    "distilbert_res = pd.read_csv('res/gender_result/distilbert_deal.csv')\n",
    "distilbert_list = distilbert_res.values.tolist()\n",
    "\n",
    "t5_res = pd.read_csv('res/gender_result/t5_deal.csv')\n",
    "t5_list = t5_res.values.tolist()\n",
    "\n",
    "bart_res = pd.read_csv('res/gender_result/bart_deal.csv')\n",
    "bart_list = bart_res.values.tolist()\n",
    "\n",
    "xlnet_res = pd.read_csv('res/gender_result/xlnet_deal.csv')\n",
    "xlnet_list = xlnet_res.values.tolist()\n",
    "\n",
    "baichuan_res = pd.read_csv('res/gender_result/baichuan-13b-base_deal.csv')\n",
    "baichuan_list = baichuan_res.values.tolist()\n",
    "\n",
    "chatglm2_res = pd.read_csv('res/gender_result/chatglm2_deal.csv')\n",
    "chatglm2_list = chatglm2_res.values.tolist()\n",
    "\n",
    "llama_res = pd.read_csv('res/gender_result/llama-2-7b_deal.csv')\n",
    "llama_list = llama_res.values.tolist()\n",
    "\n",
    "opt_res = pd.read_csv('res/gender_result/opt-iml-30b_deal.csv')\n",
    "opt_list = opt_res.values.tolist()\n",
    "\n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter(x=x, y=y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    ax.set_title(label, fontsize=10)\n",
    "    # sns.regplot(x=x,y=y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,linestyle='-',color=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'income (dollar/hour)', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination risk', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "# size_legend = ax[2,3].legend(*scatter3.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=True, fontsize=15, title_fontsize=15,  bbox_to_anchor=(1, 0, 0.5, 1))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "size_legend = ax[0,3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=15, \n",
    "                            title_fontsize=15,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "plt.savefig(\"salary.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as optimize\n",
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "selected_jobs = np.loadtxt('occ.txt', encoding='utf-8', dtype=str)\n",
    "selected_jobs = selected_jobs.tolist()\n",
    "\n",
    "with open(\"professional_income_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "\n",
    "bert_result = pd.read_csv('res/gender_result/bert_deal.csv')\n",
    "bert_list = bert_result.values.tolist()\n",
    "\n",
    "roberta_result = pd.read_csv('res/gender_result/roberta_deal.csv')\n",
    "roberta_list = roberta_result.values.tolist()\n",
    "\n",
    "gpt2_result = pd.read_csv('res/gender_result/gpt2_deal.csv')\n",
    "gpt2_list = gpt2_result.values.tolist()\n",
    "\n",
    "albert_res = pd.read_csv('res/gender_result/albert_deal.csv')\n",
    "albert_list = albert_res.values.tolist()\n",
    "\n",
    "distilbert_res = pd.read_csv('res/gender_result/distilbert_deal.csv')\n",
    "distilbert_list = distilbert_res.values.tolist()\n",
    "\n",
    "t5_res = pd.read_csv('res/gender_result/t5_deal.csv')\n",
    "t5_list = t5_res.values.tolist()\n",
    "\n",
    "bart_res = pd.read_csv('res/gender_result/bart_deal.csv')\n",
    "bart_list = bart_res.values.tolist()\n",
    "\n",
    "xlnet_res = pd.read_csv('res/gender_result/xlnet_deal.csv')\n",
    "xlnet_list = xlnet_res.values.tolist()\n",
    "\n",
    "baichuan_res = pd.read_csv('res/gender_result/baichuan-13b-base_deal.csv')\n",
    "baichuan_list = baichuan_res.values.tolist()\n",
    "\n",
    "chatglm2_res = pd.read_csv('res/gender_result/chatglm2_deal.csv')\n",
    "chatglm2_list = chatglm2_res.values.tolist()\n",
    "\n",
    "llama_res = pd.read_csv('res/gender_result/llama-2-7b_deal.csv')\n",
    "llama_list = llama_res.values.tolist()\n",
    "\n",
    "opt_res = pd.read_csv('res/gender_result/opt-iml-30b_deal.csv')\n",
    "opt_list = opt_res.values.tolist()\n",
    "\n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    scatter = ax.scatter(x=x, y=y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"], cmap='viridis')\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,linestyle='-',color=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(10, 2.7))\n",
    "\n",
    "fig.text(0.5, -0.03, 'income (dollar/hour)', ha='center', fontsize=8) \n",
    "fig.text(0.08, 0.5, 'overall discrimination risk', va='center', rotation='vertical', fontsize=8) \n",
    "\n",
    "\n",
    "scatter1, llama_coef = my_plot(state11,\"llama\", ax[3])\n",
    "scatter2, t5_coef = my_plot(state7,\"t5\", ax[2])\n",
    "scatter3, gpt2_coef = my_plot(state1, 'gpt2', ax[1])\n",
    "scatter4, bert_coef = my_plot(state2, 'bert', ax[0])\n",
    "\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "#size_legend = ax[3].legend(*scatter4.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=False, fontsize=10, title_fontsize=10,  bbox_to_anchor=(1, 0, 1, 3))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "size_legend = ax[3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=9, \n",
    "                            title_fontsize=9,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[3].add_artist(size_legend)\n",
    "\n",
    "ax[0].set_ylim(-0.05,1.05)\n",
    "ax[1].set_ylim(-0.05,1.05)\n",
    "ax[2].set_ylim(-0.05,1.05)\n",
    "ax[3].set_ylim(-0.05,1.05)\n",
    "ax[0].set_title('BERT', fontsize=10)\n",
    "ax[1].set_title('GPT-2', fontsize=10)\n",
    "ax[2].set_title('T5', fontsize=10)\n",
    "ax[3].set_title('Llama2', fontsize=10)\n",
    "\n",
    "\n",
    "plt.savefig(\"salary4m.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55082ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as optimize\n",
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "selected_jobs = np.loadtxt('occ.txt', encoding='utf-8', dtype=str)\n",
    "selected_jobs = selected_jobs.tolist()\n",
    "\n",
    "with open(\"professional_income_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "\n",
    "bert_result = pd.read_csv('res/gender_result/bert_deal.csv')\n",
    "bert_list = bert_result.values.tolist()\n",
    "\n",
    "roberta_result = pd.read_csv('res/gender_result/roberta_deal.csv')\n",
    "roberta_list = roberta_result.values.tolist()\n",
    "\n",
    "gpt2_result = pd.read_csv('res/gender_result/gpt2_deal.csv')\n",
    "gpt2_list = gpt2_result.values.tolist()\n",
    "\n",
    "albert_res = pd.read_csv('res/gender_result/albert_deal.csv')\n",
    "albert_list = albert_res.values.tolist()\n",
    "\n",
    "distilbert_res = pd.read_csv('res/gender_result/distilbert_deal.csv')\n",
    "distilbert_list = distilbert_res.values.tolist()\n",
    "\n",
    "t5_res = pd.read_csv('res/gender_result/t5_deal.csv')\n",
    "t5_list = t5_res.values.tolist()\n",
    "\n",
    "bart_res = pd.read_csv('res/gender_result/bart_deal.csv')\n",
    "bart_list = bart_res.values.tolist()\n",
    "\n",
    "xlnet_res = pd.read_csv('res/gender_result/xlnet_deal.csv')\n",
    "xlnet_list = xlnet_res.values.tolist()\n",
    "\n",
    "baichuan_res = pd.read_csv('res/gender_result/baichuan-13b-base_deal.csv')\n",
    "baichuan_list = baichuan_res.values.tolist()\n",
    "\n",
    "chatglm2_res = pd.read_csv('res/gender_result/chatglm2_deal.csv')\n",
    "chatglm2_list = chatglm2_res.values.tolist()\n",
    "\n",
    "llama_res = pd.read_csv('res/gender_result/llama-2-7b_deal.csv')\n",
    "llama_list = llama_res.values.tolist()\n",
    "\n",
    "opt_res = pd.read_csv('res/gender_result/opt-iml-30b_deal.csv')\n",
    "opt_list = opt_res.values.tolist()\n",
    "\n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state, label, ax):\n",
    "    y = np.array([d[\"risk\"] for d in state])\n",
    "    x = np.array([d[\"income\"] for d in state])\n",
    "    s = np.array([1+d[\"num\"]**(1/2) for d in state])\n",
    "    w = np.array([d[\"num\"] for d in state])\n",
    "    c = set_color(label)\n",
    "    \n",
    "    scatter = ax.scatter(x=x, y=y, s=s, c=c, alpha=0.5, label=state[0][\"model_id\"])\n",
    "\n",
    "    X = sm.add_constant(x)\n",
    "    model_wls = sm.WLS(y, X, weights=w).fit()\n",
    "\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    X_ = np.linspace(x_min, x_max, 100)\n",
    "    X_plot = sm.add_constant(X_)\n",
    "    Y_pred = model_wls.predict(X_plot)\n",
    "\n",
    "    ax.plot(X_, Y_pred, linestyle='-', color=c, linewidth=2, label=\"WLS\")\n",
    "\n",
    "    from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "    prstd, iv_l, iv_u = wls_prediction_std(model_wls,alpha=0.5) \n",
    "\n",
    "    sorted_index = np.argsort(x)\n",
    "    x_sorted = x[sorted_index]\n",
    "    iv_l_sorted = iv_l[sorted_index]\n",
    "    iv_u_sorted = iv_u[sorted_index]\n",
    "    ax.fill_between(x_sorted, iv_l_sorted, iv_u_sorted, color=c, alpha=0.1)\n",
    "    print(x)\n",
    "\n",
    "    return scatter, model_wls.params[1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(10, 2.7))\n",
    "\n",
    "fig.text(0.5, -0.03, 'income (dollar/hour)', ha='center', fontsize=8) \n",
    "fig.text(0.08, 0.5, 'overall discrimination risk', va='center', rotation='vertical', fontsize=8) \n",
    "\n",
    "\n",
    "\n",
    "scatter1, llama_coef = my_plot(state11,\"llama\", ax[3])\n",
    "scatter2, t5_coef = my_plot(state7,\"t5\", ax[2])\n",
    "scatter3, gpt2_coef = my_plot(state1, 'gpt2', ax[1])\n",
    "scatter4, bert_coef = my_plot(state2, 'bert', ax[0])\n",
    "\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "#size_legend = ax[3].legend(*scatter4.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=False, fontsize=10, title_fontsize=10,  bbox_to_anchor=(1, 0, 1, 3))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "size_legend = ax[3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=9, \n",
    "                            title_fontsize=9,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[3].add_artist(size_legend)\n",
    "\n",
    "ax[0].set_ylim(-0.05,1.05)\n",
    "ax[1].set_ylim(-0.05,1.05)\n",
    "ax[2].set_ylim(-0.05,1.05)\n",
    "ax[3].set_ylim(-0.05,1.05)\n",
    "ax[0].set_title('BERT', fontsize=10)\n",
    "ax[1].set_title('GPT-2', fontsize=10)\n",
    "ax[2].set_title('T5', fontsize=10)\n",
    "ax[3].set_title('Llama2', fontsize=10)\n",
    "\n",
    "\n",
    "plt.savefig(\"salary4m.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as optimize\n",
    "import json\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "selected_jobs = np.loadtxt('occ.txt', encoding='utf-8', dtype=str)\n",
    "selected_jobs = selected_jobs.tolist()\n",
    "\n",
    "with open(\"professional_edu_ranking.json\") as f:\n",
    "    income=json.load(f)\n",
    "#print(income)\n",
    "\n",
    "\n",
    "bert_result = pd.read_csv('res/gender_result/bert_deal.csv')\n",
    "bert_list = bert_result.values.tolist()\n",
    "\n",
    "roberta_result = pd.read_csv('res/gender_result/roberta_deal.csv')\n",
    "roberta_list = roberta_result.values.tolist()\n",
    "\n",
    "gpt2_result = pd.read_csv('res/gender_result/gpt2_deal.csv')\n",
    "gpt2_list = gpt2_result.values.tolist()\n",
    "\n",
    "albert_res = pd.read_csv('res/gender_result/albert_deal.csv')\n",
    "albert_list = albert_res.values.tolist()\n",
    "\n",
    "distilbert_res = pd.read_csv('res/gender_result/distilbert_deal.csv')\n",
    "distilbert_list = distilbert_res.values.tolist()\n",
    "\n",
    "t5_res = pd.read_csv('res/gender_result/t5_deal.csv')\n",
    "t5_list = t5_res.values.tolist()\n",
    "\n",
    "bart_res = pd.read_csv('res/gender_result/bart_deal.csv')\n",
    "bart_list = bart_res.values.tolist()\n",
    "\n",
    "xlnet_res = pd.read_csv('res/gender_result/xlnet_deal.csv')\n",
    "xlnet_list = xlnet_res.values.tolist()\n",
    "\n",
    "baichuan_res = pd.read_csv('res/gender_result/baichuan-13b-base_deal.csv')\n",
    "baichuan_list = baichuan_res.values.tolist()\n",
    "\n",
    "chatglm2_res = pd.read_csv('res/gender_result/chatglm2_deal.csv')\n",
    "chatglm2_list = chatglm2_res.values.tolist()\n",
    "\n",
    "llama_res = pd.read_csv('res/gender_result/llama-2-7b_deal.csv')\n",
    "llama_list = llama_res.values.tolist()\n",
    "\n",
    "opt_res = pd.read_csv('res/gender_result/opt-iml-30b_deal.csv')\n",
    "opt_list = opt_res.values.tolist()\n",
    "\n",
    "\"\"\" new version \"\"\"\n",
    "num_data = pd.read_csv('data/occupation_population.csv')\n",
    "num_data = num_data.values.tolist()\n",
    "\n",
    "def count_num(job,data):\n",
    "    num = 0\n",
    "    for row in num_data:\n",
    "        if row[0].strip() == job.strip():\n",
    "            num = int(row[1])\n",
    "            break\n",
    "    return num\n",
    "\n",
    "def set_color(model_id):\n",
    "    if model_id == \"gpt2\":\n",
    "        return \"navy\"\n",
    "    if model_id == \"bert\":\n",
    "        return \"blueviolet\"\n",
    "    if model_id == \"roberta\":\n",
    "        return \"crimson\"\n",
    "    if model_id == \"albert\":\n",
    "        return \"dodgerblue\"\n",
    "    if model_id == \"distilbert\":\n",
    "        return \"sienna\"\n",
    "    if model_id == \"bart\":\n",
    "        return \"slategrey\"\n",
    "    if model_id == \"t5\":\n",
    "        return \"darkorange\"\n",
    "    if model_id == 'xlnet':\n",
    "        return \"limegreen\"\n",
    "    if model_id == 'opt':\n",
    "        return \"gold\"\n",
    "    if model_id == \"baichuan\":\n",
    "        return \"tan\"\n",
    "    if model_id == \"llama\":\n",
    "        return \"maroon\"\n",
    "    if model_id == \"chatglm2\":\n",
    "        return \"darkolivegreen\"\n",
    "    \n",
    "    \n",
    "jobs={x[0]:x[1] for x in income}\n",
    "for job in jobs: \n",
    "    if count_num(job, num_data) ==0:\n",
    "        print(job)\n",
    "\n",
    "\n",
    "state1=[]\n",
    "state2=[]\n",
    "state3=[]\n",
    "state4=[]\n",
    "state5=[]\n",
    "state6=[]\n",
    "state7=[]\n",
    "state8=[]\n",
    "state9=[]\n",
    "state10=[]\n",
    "state11=[]\n",
    "state12=[]\n",
    "\n",
    "for row in gpt2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state1.append({\"occu\": row[0],\"risk\": row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"GPT-2\", \"income\": jobs[row[0]]})\n",
    "for row in bert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state2.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BERT\", \"income\": jobs[row[0]]})\n",
    "for row in roberta_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state3.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"RoBERTa\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in albert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state4.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ALBERT\", \"income\": jobs[row[0]]})        \n",
    "\n",
    "for row in distilbert_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state5.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"distilBERT\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in bart_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state6.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"BART\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in t5_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state7.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"T5\", \"income\": jobs[row[0]]})    \n",
    "\n",
    "for row in xlnet_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state8.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"XLNet\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in opt_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state9.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"OPT-IML\", \"income\": jobs[row[0]]})\n",
    "\n",
    "for row in baichuan_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state10.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"Baichuan\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in llama_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state11.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"LLaMA2\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "for row in chatglm2_list:\n",
    "    if row[0] in jobs and row[0] in selected_jobs:\n",
    "        state12.append({\"occu\": row[0],\"risk\":  row[1] * 2, \"num\": count_num(row[0],num_data), \"model_id\": \"ChatGLM\", \"income\": jobs[row[0]]})\n",
    "        \n",
    "def my_plot(state,label,ax):\n",
    "    y = [ d[\"risk\"] for d in state]\n",
    "    x = [ d[\"income\"] for d in state]\n",
    "    s = [ 1+d[\"num\"]**(1/2) for d in state ] \n",
    "    w = [ d[\"num\"] for d in state ]\n",
    "    c = set_color(label)\n",
    "    print(len(x),len(y),len(c),len(s))\n",
    "    scatter = ax.scatter(x, y, s=s, c=c, alpha = 0.5, label=state[0][\"model_id\"])\n",
    "    ax.set_title(label, fontsize=10)\n",
    "    # sns.regplot(x=x,y=y,ax=ax,color=c,scatter=False,label=\"OLS\")\n",
    "    X=np.array(x).reshape(-1, 1)\n",
    "    Y=np.array(y).reshape(-1, 1)\n",
    "    model=LinearRegression()\n",
    "    model.fit(X, Y)#fit WLS using sample_weights\n",
    "    WLS =LinearRegression()\n",
    "    WLS.fit(X, Y, sample_weight = w)\n",
    "    # print('model')\n",
    "    # print(model.intercept_, model.coef_)\n",
    "    # print('WLS')\n",
    "    # print(WLS.intercept_, WLS.coef_)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    X_ = np.linspace(x_min, x_max, 15).reshape(-1, 1)\n",
    "    ax.plot(X_,WLS.intercept_+WLS.coef_*X_,linestyle='-',color=c,linewidth=2,label=\"WLS\")\n",
    "    return scatter, model.coef_[0][0]\n",
    "#for x in state:\n",
    "#    plt.scatter(x[\"risk\"], x[\"income\"], s=math.sqrt(x[\"num\"])/3, c=set_color(x[\"model_id\"]), alpha = 0.5, label=x[\"model_id\"])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.text(0.5, 0.04, 'income (dollar/hour)', ha='center', fontsize=15) \n",
    "fig.text(0.07, 0.5, 'overall discrimination risk', va='center', rotation='vertical', fontsize=15) \n",
    "\n",
    "scatter1, opt_coef = my_plot(state9,\"opt\", ax[0,0])\n",
    "scatter2, baichuan_coef = my_plot(state10,\"baichuan\", ax[0,1])\n",
    "scatter3, llama_coef = my_plot(state11,\"llama\", ax[0,2])\n",
    "scatter4, chatglm2_coef = my_plot(state12,\"chatglm2\", ax[0,3])\n",
    "scatter5, t5_coef = my_plot(state7,\"t5\", ax[1,0])\n",
    "scatter6, bart_coef = my_plot(state6,\"bart\", ax[1,1])\n",
    "scatter7, roberta_coef = my_plot(state3,\"roberta\", ax[1,2])\n",
    "scatter8, albert_coef = my_plot(state4,\"albert\", ax[1,3])\n",
    "scatter9, gpt2_coef = my_plot(state1, 'gpt2', ax[2,0])\n",
    "scatter10, bert_coef = my_plot(state2, 'bert', ax[2,1])\n",
    "scatter11, xlnet_coef = my_plot(state8, 'xlnet', ax[2,2])\n",
    "scatter12, distilbert_coef = my_plot(state5, 'distilbert', ax[2,3])\n",
    "\n",
    "kw1 = dict(prop=\"sizes\",  \n",
    "       num=4, color='black', alpha=0.5, \n",
    "       func=lambda s:(s-1)**(2), \n",
    "       linewidth=0)  \n",
    "# size_legend = ax[2,3].legend(*scatter3.legend_elements(**kw1), loc='lower left', title=\"population\", frameon=True, fontsize=15, title_fontsize=15,  bbox_to_anchor=(1, 0, 0.5, 1))  # 与上边同理\n",
    "#legend2 = ax.legend(*scatter.legend_elements(prop='sizes', num = 6), loc='lower left',title='population', func=lambda s:(s-1)**2 , bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "size_legend = ax[0,3].legend(*scatter4.legend_elements(**kw1), \n",
    "                            loc='upper left', \n",
    "                            title=\"population\", \n",
    "                            frameon=True, \n",
    "                            edgecolor='black', \n",
    "                            fontsize=15, \n",
    "                            title_fontsize=15,  \n",
    "                            bbox_to_anchor=(1.02, 1.025))\n",
    "\n",
    "ax[0,0].set_ylim(-0.05,1.05)\n",
    "ax[0,1].set_ylim(-0.05,1.05)\n",
    "ax[0,2].set_ylim(-0.05,1.05)\n",
    "ax[0,3].set_ylim(-0.05,1.05)\n",
    "ax[1,0].set_ylim(-0.05,1.05)\n",
    "ax[1,1].set_ylim(-0.05,1.05)\n",
    "ax[1,2].set_ylim(-0.05,1.05)\n",
    "ax[1,3].set_ylim(-0.05,1.05)\n",
    "ax[2,0].set_ylim(-0.05,1.05)\n",
    "ax[2,1].set_ylim(-0.05,1.05)\n",
    "ax[2,2].set_ylim(-0.05,1.05)\n",
    "ax[2,3].set_ylim(-0.05,1.05)\n",
    "\n",
    "plt.savefig(\"education_year.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
